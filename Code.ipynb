{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Code",
      "provenance": [],
      "authorship_tag": "ABX9TyPSVizkDzCxI2ZKoZeDfHqm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaraFernandes98/Fire-Detection---Firefront/blob/main/Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Wrs6jt9-fxlW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "244c9f48-8f10-446f-e1a2-9a539dded435"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import os,sys\n",
        "import cv2\n",
        "import matplotlib.image as mpimg\n",
        "import imageio\n",
        "import pylab\n",
        "import glob\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, average_precision_score, confusion_matrix, f1_score\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from tensorflow import Tensor\n",
        "from tensorflow.keras import layers, losses, backend\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from sklearn.utils import class_weight\n",
        "from tqdm import tqdm\n",
        "from keras.models import load_model\n",
        "\n",
        "from math import floor\n",
        "import random\n",
        "import math\n",
        "import imutils\n",
        "from statistics import median\n",
        "from matplotlib import transforms\n",
        "\n",
        "\n",
        "# Random seed fixation\n",
        "tf.random.set_seed(666)\n",
        "np.random.seed(666)\n"
      ],
      "metadata": {
        "id": "Qoh8SKi3gEfq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load images"
      ],
      "metadata": {
        "id": "GAEM_0OVmTt_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images_ssl_tain(path):\n",
        "  images = []\n",
        "  for filename in os.listdir(path):\n",
        "      image = tf.io.read_file(path+'/'+filename)\n",
        "      image = tf.image.decode_jpeg(image, channels=3)\n",
        "      image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "      if image is not None:\n",
        "          images.append(image)\n",
        "  return np.array(images)\n",
        "\n",
        "def load_images_supervised(path):\n",
        "  data = pd.read_csv(path, iterator=True)\n",
        "  dir = path.split('.')\n",
        "  dataset= list(data)\n",
        "  dataset = np.array(dataset)\n",
        "  images=[]\n",
        "  labels = []\n",
        "  img_paths = []\n",
        "  for i in dataset:\n",
        "    for a in i:\n",
        "      if os.path.exists(path[:-9]+a[0]):\n",
        "        image_string = tf.io.read_file(path[:-9]+a[0])\n",
        "        image = tf.image.decode_png(image_string, channels=3)\n",
        "        image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "        label = a[1]\n",
        "        images.append(image)\n",
        "        labels.append(label)\n",
        "\n",
        "  return images, labels\n",
        "\n",
        "Pssl = '/content/drive/MyDrive/Tese/Bombeiros/All_crop_resized/to_train_ssl'\n",
        "ssl_images = load_images_ssl_tain(Pssl)\n",
        "\n",
        "Psupervised = '/content/drive/MyDrive/Tese/Bombeiros/All_crop_resized/supervised/labels.csv'\n",
        "sup_images, sup_labels = load_images_supervised(Psupervised)\n"
      ],
      "metadata": {
        "id": "qae_nfd5mHoN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **SSL Phase**\n",
        "\n"
      ],
      "metadata": {
        "id": "-NtGuLL365Hl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Autoencoder"
      ],
      "metadata": {
        "id": "bYLq4f9T7TdB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encoderModel():\n",
        "  model = tf.keras.Sequential()\n",
        "  #------Encoder------#\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "  model.add(layers.AveragePooling2D((2, 2), padding='same'))\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "  model.add(layers.AveragePooling2D((2, 2), padding='same'))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "  model.add(layers.AveragePooling2D((2, 2), padding='same'))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "  model.add(layers.AveragePooling2D((2, 2), padding='same'))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='tanh', padding='same'))\n",
        "  model.add(layers.AveragePooling2D((2, 2), padding='same'))\n",
        "  \n",
        "  #------Decoder------#\n",
        "  model.add(layers.Conv2DTranspose(64, (3, 3), activation='relu', strides=2, padding='same')) \n",
        "  model.add(layers.Conv2DTranspose(64, (3, 3), activation='relu', strides=2, padding='same'))\n",
        "  model.add(layers.Conv2DTranspose(64, (3, 3), activation='relu', strides=2, padding='same'))\n",
        "  model.add(layers.Conv2DTranspose(32, (3, 3), activation='relu', strides=2, padding='same'))\n",
        "  model.add(layers.Conv2DTranspose(32, (3, 3), activation='relu', strides=2, padding='same'))\n",
        "  model.add(layers.Conv2D(3, (3, 3), activation='relu', padding='same'))\n",
        "  return model"
      ],
      "metadata": {
        "id": "ap0GQDZw7AT5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For autoencoder\n",
        "class ColorAugment(object):\n",
        "    def __call__(self, sample, p=1):        \n",
        "        # Random flips\n",
        "        #sample = self._random_apply(tf.image.flip_left_right, sample, p=0.5)\n",
        "        \n",
        "        # Randomly apply transformation (color distortions) with probability p.\n",
        "        sample = self._random_apply(self._color_jitter, sample, p=1)\n",
        "        return sample\n",
        "\n",
        "    def _color_jitter(self, x,s=1):\n",
        "        # one can also shuffle the order of following augmentations\n",
        "        # each time they are applied.\n",
        "        imgs = []\n",
        "        for i in x:\n",
        "          i = tf.image.random_saturation(i, lower=1-0.3*s, upper=1+0.3*s)\n",
        "          i = tf.image.random_hue(i, max_delta=0.2*s)\n",
        "          i = tf.clip_by_value(i, 0, 1)\n",
        "          imgs.append(i)\n",
        "        return np.array(imgs)\n",
        "    \n",
        "\n",
        "    def _random_apply(self, func, x, p):\n",
        "        return tf.cond(\n",
        "          tf.less(tf.random.uniform([], minval=0, maxval=1, dtype=tf.float32),\n",
        "                  tf.cast(p, tf.float32)),\n",
        "          lambda: func(x),\n",
        "          lambda: x)\n",
        "\n",
        "class CropAugment(object):\n",
        "   def __call__(self, sample,p=1):        \n",
        "        sample = self._random_apply(self._random_crop, sample, p=1)\n",
        "        return sample\n",
        "\n",
        "   def _random_crop(self,x):\n",
        "      imgs = []\n",
        "      for i in x:\n",
        "            i = tf.image.random_flip_left_right(i)\n",
        "            size = np.random.randint(100,200)\n",
        "            i = tf.image.random_crop(i, [size,size,3])\n",
        "            i = tf.image.resize(i,[224,224])\n",
        "            imgs.append(i)\n",
        "      return np.array(imgs)\n",
        "\n",
        "   def _random_apply(self, func, x, p):\n",
        "        return tf.cond(\n",
        "          tf.less(tf.random.uniform([], minval=0, maxval=1, dtype=tf.float32),\n",
        "                  tf.cast(p, tf.float32)),\n",
        "          lambda: func(x),\n",
        "          lambda: x)\n",
        "\n",
        "\n",
        "class RotationAugment(object):\n",
        "   def __call__(self, sample,p=1):        \n",
        "        sample = self._random_apply(self._random_rotation, sample, p=1)\n",
        "        return sample\n",
        "\n",
        "   def _rotatedRectWithMaxArea(self, w, h, angle):\n",
        "      \"\"\"\n",
        "      Given a rectangle of size wxh that has been rotated by 'angle' (in\n",
        "      radians), computes the width and height of the largest possible\n",
        "      axis-aligned rectangle (maximal area) within the rotated rectangle.\n",
        "      \"\"\"\n",
        "      if w <= 0 or h <= 0:\n",
        "        return 0,0\n",
        "\n",
        "      width_is_longer = w >= h\n",
        "      side_long, side_short = (w,h) if width_is_longer else (h,w)\n",
        "\n",
        "      # since the solutions for angle, -angle and 180-angle are all the same,\n",
        "      # if suffices to look at the first quadrant and the absolute values of sin,cos:\n",
        "      sin_a, cos_a = abs(math.sin(angle)), abs(math.cos(angle))\n",
        "      if side_short <= 2.*sin_a*cos_a*side_long or abs(sin_a-cos_a) < 1e-10:\n",
        "        # half constrained case: two crop corners touch the longer side,\n",
        "        #   the other two corners are on the mid-line parallel to the longer line\n",
        "        x = 0.5*side_short\n",
        "        wr,hr = (x/sin_a,x/cos_a) if width_is_longer else (x/cos_a,x/sin_a)\n",
        "      else:\n",
        "        # fully constrained case: crop touches all 4 sides\n",
        "        cos_2a = cos_a*cos_a - sin_a*sin_a\n",
        "        wr,hr = (w*cos_a - h*sin_a)/cos_2a, (h*cos_a - w*sin_a)/cos_2a\n",
        "\n",
        "      return wr,hr\n",
        "\n",
        "   def _random_rotation(self,x):\n",
        "      imgs = []\n",
        "      for i in x:\n",
        "        angle = np.random.randint(1,20)\n",
        "        wr, hr = self._rotatedRectWithMaxArea(224,224,math.radians(angle))\n",
        "        # Use PIL or other library of the sort to rotate\n",
        "        i = imutils.rotate(np.array(i), angle=angle)\n",
        "        i = tf.image.central_crop(i, float(hr)/224) \n",
        "        i = tf.image.resize(i, [224,224])\n",
        "        imgs.append(i)\n",
        "      return np.array(imgs)\n",
        "      #imgs.append(i)\n",
        "      #return np.array(imgs)\n",
        "\n",
        "   def _random_apply(self, func, x, p):\n",
        "        return tf.cond(\n",
        "          tf.less(tf.random.uniform([], minval=0, maxval=1, dtype=tf.float32),\n",
        "                  tf.cast(p, tf.float32)),\n",
        "          lambda: func(x),\n",
        "          lambda: x)\n",
        "\n",
        "class dataTransforms(object):\n",
        "  def __call__(self, sample): \n",
        "        # Build the augmentation pipeline\n",
        "        color_augmentation = ColorAugment()\n",
        "        rotation_augmentation = RotationAugment()\n",
        "        sample = self._random_apply(rotation_augmentation._random_rotation, sample, p=1)\n",
        "        sample = self._random_apply(color_augmentation._color_jitter, sample, p=1)\n",
        "        return sample\n",
        "\n",
        "  def _random_apply(self, func, x, p):\n",
        "        return tf.cond(\n",
        "          tf.less(tf.random.uniform([], minval=0, maxval=1, dtype=tf.float32),\n",
        "                  tf.cast(p, tf.float32)),\n",
        "          lambda: func(x),\n",
        "          lambda: x)\n",
        "        \n",
        "\n",
        "\n",
        "# Build the augmentation pipeline\n",
        "color_augmentation = tf.keras.Sequential([layers.Lambda(ColorAugment())])\n",
        "crop_augmentation = tf.keras.Sequential([layers.Lambda(CropAugment())])\n",
        "rotation_augmentation = tf.keras.Sequential([layers.Lambda(RotationAugment())])\n",
        "transformation = tf.keras.Sequential([layers.Lambda(dataTransforms())])\n"
      ],
      "metadata": {
        "id": "jCWQRCBm6POs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dataAugmentation(dataset, nImgs, transform, per):\n",
        "  \"\"\"\n",
        "    dataset: set with images\n",
        "    nImgs: initial images (without transformations) used to train the network \n",
        "    transform: type of transformation to apply to images\n",
        "    per: transformations are applied to a percentage of nImgs\n",
        "\n",
        "    The total number of images used to train the network is nImgs*(1+per) \n",
        "\n",
        "    retrun: final images with transformations applied\n",
        "\n",
        "  \"\"\"\n",
        "  train_auto_imgs = []\n",
        "  train_auto_imgs = dataset[:nImgs]\n",
        "  print(len(train_auto_imgs))\n",
        "  if transform == 'color':\n",
        "    train_auto_imgs = np.concatenate((train_auto_imgs, color_augmentation(dataset[:floor(nImgs*per)])))\n",
        "  elif transform == 'rot':\n",
        "    train_auto_imgs = np.concatenate((train_auto_imgs, rotation_augmentation(dataset[:floor(nImgs*per)])))\n",
        "  elif transform == 'cor_rot':\n",
        "    train_auto_imgs = np.concatenate((train_auto_imgs, color_augmentation(dataset[:floor(nImgs*per*0.5)])))\n",
        "    train_auto_imgs = np.concatenate((train_auto_imgs, rotation_augmentation(dataset[floor(nImgs*per*0.5):floor(nImgs*per)])))\n",
        "  elif transform == 'cor+rot':\n",
        "    train_auto_imgs = np.concatenate((train_auto_imgs, transformation(dataset[:floor(nImgs*per)])))\n",
        "  elif transform == '4x':\n",
        "    train_auto_imgs = np.concatenate((train_auto_imgs, color_augmentation(dataset[:floor(nImgs*per)])))\n",
        "    train_auto_imgs = np.concatenate((train_auto_imgs, rotation_augmentation(dataset[:floor(nImgs*per)])))\n",
        "    train_auto_imgs = np.concatenate((train_auto_imgs, transformation(dataset[:floor(nImgs*per)])))\n",
        "  elif transform == 'nocor':\n",
        "    train_auto_imgs = np.concatenate((train_auto_imgs, rotation_augmentation(dataset[:floor(nImgs*per)])))\n",
        "    train_auto_imgs = np.concatenate((train_auto_imgs, crop_augmentation(dataset[:floor(nImgs*per)])))\n",
        "    train_auto_imgs = np.concatenate((train_auto_imgs, crop_augmentation(rotation_augmentation(dataset[:floor(nImgs*per)]))))\n",
        "  elif transform == 'crop+flip':\n",
        "    train_auto_imgs = np.concatenate((train_auto_imgs, crop_augmentation(dataset[:floor(nImgs*per)])))\n",
        "  elif transform == '5x':\n",
        "    train_auto_imgs = np.concatenate((train_auto_imgs, color_augmentation(dataset[:floor(nImgs*per)])))\n",
        "    train_auto_imgs = np.concatenate((train_auto_imgs, rotation_augmentation(dataset[:floor(nImgs*per)])))\n",
        "    train_auto_imgs = np.concatenate((train_auto_imgs, transformation(dataset[:floor(nImgs*per)])))\n",
        "    train_auto_imgs = np.concatenate((train_auto_imgs, crop_augmentation(dataset[:floor(nImgs*per)])))\n",
        "  \n",
        "  return np.array(train_auto_imgs)"
      ],
      "metadata": {
        "id": "IKYS6bhy7Xss"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get model\n",
        "autoencoder = encoderModel()\n",
        "autoencoder.compile(\n",
        "    optimizer='adam',\n",
        "    loss=losses.MeanSquaredError()\n",
        ")\n",
        "\n",
        "#Apply transformation to the images\n",
        "images = dataAugmentation(ssl_images, 1000, 'color', 1) \n",
        "images = shuffle(images)\n",
        "train, val = images[:floor(len(images)*0.9)], images[floor(len(images)*0.9):]\n",
        "\n",
        "#train images\n",
        "history = autoencoder.fit(train, train,   \n",
        "                  epochs=60,\n",
        "                  batch_size=75,\n",
        "                  validation_data =(val, val), \n",
        "                  callbacks=[],\n",
        "                  shuffle=True)\n",
        "\n",
        "\n",
        "# Save the model.\n",
        "model_name = 'model_name'\n",
        "Pmodel = '/content/drive/MyDrive/Tese/code/Models/Self_supervised/' + model_name \n",
        "autoencoder.save(Pmodel)"
      ],
      "metadata": {
        "id": "77Bu8jpn7fbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SimCLR"
      ],
      "metadata": {
        "id": "bCkCoBhY7q5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------Model-------------------#\n",
        "\n",
        "def create_encoder():\n",
        "    model = tf.keras.Sequential()\n",
        "    # #------Encoder------#\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.AveragePooling2D((2, 2), padding='same'))\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.AveragePooling2D((2, 2), padding='same'))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.AveragePooling2D((2, 2), padding='same'))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.AveragePooling2D((2, 2), padding='same'))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='tanh', padding='same'))\n",
        "    model.add(layers.AveragePooling2D((2, 2), padding='same'))\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "#Projection head\n",
        "def add_projection_head(encoder):\n",
        "    inputs = tf.keras.Input(shape=(224,224,3))\n",
        "    for layer in encoder.layers:\n",
        "        layer.trainable = True\n",
        "    features = encoder(inputs)\n",
        "    features = layers.Flatten()(features)\n",
        "    projection_0 = layers.Dense(64)(features)\n",
        "    projection_0 = layers.Activation(\"relu\")(projection_0)\n",
        "    projection_1 = layers.Dense(64)(projection_0)\n",
        "\n",
        "\n",
        "    model = Model(inputs, projection_1)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "QpOn4OyccefK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#---------------Data Augmentation-------------------#\n",
        "def random_resize_crop(image, crop_size=224):\n",
        "    imgs=[]\n",
        "    i=image[0]\n",
        "    for i in image:\n",
        "      print(i)\n",
        "      size = np.random.randint(100,200)\n",
        "      i = tf.image.random_crop(i, [size,size,3])\n",
        "      i = tf.image.resize(i,[crop_size,crop_size])\n",
        "      imgs.append(i)\n",
        "    return np.array(i)\n",
        "\n",
        "def flip_random_crop(image):\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = random_resize_crop(image)\n",
        "    return image\n",
        "\n",
        "\n",
        "def color_jitter(x, strength=1):    \n",
        "    x = tf.image.random_saturation(x, lower=1 - 0.3 * strength, upper=1 + 0.3 * strength)\n",
        "    x = tf.image.random_hue(x, max_delta=0.2 * strength)\n",
        "    x = tf.clip_by_value(x, 0, 1)\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "def _rotatedRectWithMaxArea( w, h, angle):\n",
        "      \"\"\"\n",
        "      Given a rectangle of size wxh that has been rotated by 'angle' (in\n",
        "      radians), computes the width and height of the largest possible\n",
        "      axis-aligned rectangle (maximal area) within the rotated rectangle.\n",
        "      \"\"\"\n",
        "      if w <= 0 or h <= 0:\n",
        "        return 0,0\n",
        "\n",
        "      width_is_longer = w >= h\n",
        "      side_long, side_short = (w,h) if width_is_longer else (h,w)\n",
        "\n",
        "      # since the solutions for angle, -angle and 180-angle are all the same,\n",
        "      # if suffices to look at the first quadrant and the absolute values of sin,cos:\n",
        "      sin_a, cos_a = abs(math.sin(angle)), abs(math.cos(angle))\n",
        "      if side_short <= 2.*sin_a*cos_a*side_long or abs(sin_a-cos_a) < 1e-10:\n",
        "        # half constrained case: two crop corners touch the longer side,\n",
        "        #   the other two corners are on the mid-line parallel to the longer line\n",
        "        x = 0.5*side_short\n",
        "        wr,hr = (x/sin_a,x/cos_a) if width_is_longer else (x/cos_a,x/sin_a)\n",
        "      else:\n",
        "        # fully constrained case: crop touches all 4 sides\n",
        "        cos_2a = cos_a*cos_a - sin_a*sin_a\n",
        "        wr,hr = (w*cos_a - h*sin_a)/cos_2a, (h*cos_a - w*sin_a)/cos_2a\n",
        "\n",
        "      return wr,hr\n",
        "\n",
        "def random_rotation(x):\n",
        "    imgs = []\n",
        "    for i in x:\n",
        "        angle = np.random.randint(1,20)\n",
        "        wr, hr = _rotatedRectWithMaxArea(224,224,math.radians(angle))\n",
        "        # Use PIL or other library of the sort to rotate\n",
        "        i = imutils.rotate(np.array(i), angle=angle)\n",
        "        i = tf.image.central_crop(i, float(hr)/224) \n",
        "        i = tf.image.resize(i, [224,224])\n",
        "        imgs.append(i)\n",
        "    return np.array(imgs)\n",
        "\n",
        "\n",
        "def random_apply(func, x, p):\n",
        "    if tf.random.uniform([], minval=0, maxval=1) < p:\n",
        "        return func(x)\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "i_Oqgv6PbkKI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/sthalles/SimCLR-tensorflow/master/utils/helpers.py\n",
        "!wget https://raw.githubusercontent.com/sthalles/SimCLR-tensorflow/master/utils/losses.py"
      ],
      "metadata": {
        "id": "3M0d7VsKYFHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "@tf.function\n",
        "def parse_images(image):\n",
        "  return image\n",
        "\n",
        "@tf.function\n",
        "def train_step(xis, xjs, model, optimizer, temperature):\n",
        "    with tf.GradientTape() as tape:\n",
        "        zis = model(xis)\n",
        "        zjs = model(xjs)\n",
        "        # normalize projection feature vectors\n",
        "        #em vez de normalizar aqui\n",
        "        zis = tf.math.l2_normalize(zis, axis=1)\n",
        "        zjs = tf.math.l2_normalize(zjs, axis=1)\n",
        "\n",
        "        z = tf.cast(tf.concat((zis, zjs), 0), dtype=tf.float32)\n",
        "        loss = 0\n",
        "        for k in range(BATCH_SIZE):\n",
        "            # Numerator (compare i,j & j,i)\n",
        "            i = k\n",
        "            j = k + BATCH_SIZE\n",
        "            # Instantiate the cosine similarity loss function\n",
        "            cosine_sim = tf.keras.losses.CosineSimilarity(axis=-1, reduction=tf.keras.losses.Reduction.NONE)\n",
        "            sim = tf.squeeze(- cosine_sim(tf.reshape(z[i], (1, -1)), tf.reshape(z[j], (1, -1))))\n",
        "            numerator = tf.math.exp(sim / temperature)\n",
        "\n",
        "            # Denominator (compare i & j to all samples apart from themselves)\n",
        "            sim_ik = - cosine_sim(tf.reshape(z[i], (1, -1)), z[tf.range(BATCH_SIZE*2) != i])\n",
        "            sim_jk = - cosine_sim(tf.reshape(z[j], (1, -1)), z[tf.range(BATCH_SIZE*2) != j])\n",
        "            denominator_ik = tf.reduce_sum(tf.math.exp(sim_ik / temperature))\n",
        "            denominator_jk = tf.reduce_sum(tf.math.exp(sim_jk / temperature))\n",
        "\n",
        "            # Calculate individual and combined losses\n",
        "            loss_ij = - tf.math.log(numerator / denominator_ik)\n",
        "            loss_ji = - tf.math.log(numerator / denominator_jk)\n",
        "            loss += loss_ij + loss_ji\n",
        "        # Divide by the total number of samples\n",
        "        loss /= (BATCH_SIZE*2)\n",
        "\n",
        "\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    return loss\n",
        "\n",
        "def train_simclr(model, dataset, optimizer, criterion,\n",
        "                 temperature=0.1, epochs=100):\n",
        "    step_wise_loss = []\n",
        "    epoch_wise_loss = []\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        for image_batch in dataset:\n",
        "            #data augmentation: create positive and negative pairs\n",
        "            a = random_apply(random_rotation,image_batch, p=1)\n",
        "            b = image_batch \n",
        "            #train model and calculate loss\n",
        "            loss = train_step(a, b, model, optimizer, temperature)\n",
        "            step_wise_loss.append(loss)\n",
        "\n",
        "        epoch_wise_loss.append(np.mean(step_wise_loss))\n",
        "        #wandb.log({\"nt_xentloss\": np.mean(step_wise_loss)})\n",
        "        \n",
        "        if epoch % 1 == 0:\n",
        "            print(\"step_wise_loss: \", step_wise_loss)\n",
        "            print(\"epoch: {} loss: {:.3f}\".format(epoch + 1, np.mean(step_wise_loss)))\n",
        "\n",
        "    return epoch_wise_loss"
      ],
      "metadata": {
        "id": "CXJka6dKcZ4q"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, \n",
        "                                                          reduction=tf.keras.losses.Reduction.SUM)\n",
        "\n",
        "decay_steps = 50 \n",
        "lr_decayed_fn = tf.keras.experimental.CosineDecay(\n",
        "    initial_learning_rate=0.01, decay_steps=decay_steps)\n",
        "optimizer = tf.keras.optimizers.Adam(lr_decayed_fn)\n",
        "\n",
        "#create model encoder + projection head\n",
        "encoder = create_encoder()\n",
        "encoder_with_projection_head = add_projection_head(encoder) \n",
        "encoder_with_projection_head.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=losses.MeanSquaredError())\n",
        "\n",
        "\n",
        "#Get transformations to apply to images\n",
        "train_ds = tf.data.Dataset.from_tensor_slices(ssl_images)\n",
        "train_ds = (\n",
        "    train_ds\n",
        "    .map(parse_images, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    .shuffle(1024)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
        ")\n",
        "\n",
        "# train network\n",
        "epoch_wise_loss  = train_simclr(encoder_with_projection_head, train_ds, optimizer, criterion,\n",
        "                 temperature=0.1, epochs=200)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epoch_wise_loss)\n",
        "plt.show()\n",
        "\n",
        "# Save model\n",
        "model_name = 'model_name'\n",
        "encoder_path = '/content/drive/MyDrive/Tese/code/Models/Self_supervised/' + model_name\n",
        "encoder.save(encoder_path)"
      ],
      "metadata": {
        "id": "HSGMEaDJctNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Barlow Twins"
      ],
      "metadata": {
        "id": "9PZQLzgE7uww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------Model--------------#\n",
        "def encoderModel(size):\n",
        "  model = tf.keras.Sequential()\n",
        "  #------Encoder------#\n",
        "  model.add(layers.Input(shape=(224,224,3)))\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "  model.add(layers.AveragePooling2D((2, 2), padding='same'))\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "  model.add(layers.AveragePooling2D((2, 2), padding='same'))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "  model.add(layers.AveragePooling2D((2, 2), padding='same'))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "  model.add(layers.AveragePooling2D((2, 2), padding='same'))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='tanh', padding='same'))\n",
        "  model.add(layers.AveragePooling2D((2, 2), padding='same'))\n",
        "\n",
        "\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(size))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Activation(\"relu\"))\n",
        "  model.add(layers.Dense(size))\n",
        "  model.add(layers.Activation(\"relu\"))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Dense(size))\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "_lGpH4OcdK1R"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#--------Data Augmentation---------#\n",
        "def random_resize_crop(image, crop_size=224):\n",
        "    size = np.random.randint(100,200)\n",
        "    image = tf.image.random_crop(image, [size,size,3])\n",
        "    image = tf.image.resize(image,[crop_size,crop_size])\n",
        "    return image\n",
        "\n",
        "def flip_random_crop(image):\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = random_resize_crop(image)\n",
        "    return image\n",
        "\n",
        "\n",
        "def color_jitter(x, strength=1):\n",
        "    x = tf.image.random_saturation(x, lower=1 - 0.3 * strength, upper=1 + 0.3 * strength)\n",
        "    x = tf.image.random_hue(x, max_delta=0.2 * strength)\n",
        "    x = tf.clip_by_value(x, 0, 1)\n",
        "    return x\n",
        "\n",
        "\n",
        "def color_drop(x):\n",
        "    x = tf.image.rgb_to_grayscale(x)\n",
        "    x = tf.tile(x, [1, 1, 3])\n",
        "    return x\n",
        "\n",
        "def _rotatedRectWithMaxArea( w, h, angle):\n",
        "      \"\"\"\n",
        "      Given a rectangle of size wxh that has been rotated by 'angle' (in\n",
        "      radians), computes the width and height of the largest possible\n",
        "      axis-aligned rectangle (maximal area) within the rotated rectangle.\n",
        "      \"\"\"\n",
        "      if w <= 0 or h <= 0:\n",
        "        return 0,0\n",
        "\n",
        "      width_is_longer = w >= h\n",
        "      side_long, side_short = (w,h) if width_is_longer else (h,w)\n",
        "\n",
        "      # since the solutions for angle, -angle and 180-angle are all the same,\n",
        "      # if suffices to look at the first quadrant and the absolute values of sin,cos:\n",
        "      sin_a, cos_a = abs(math.sin(angle)), abs(math.cos(angle))\n",
        "      if side_short <= 2.*sin_a*cos_a*side_long or abs(sin_a-cos_a) < 1e-10:\n",
        "        # half constrained case: two crop corners touch the longer side,\n",
        "        #   the other two corners are on the mid-line parallel to the longer line\n",
        "        x = 0.5*side_short\n",
        "        wr,hr = (x/sin_a,x/cos_a) if width_is_longer else (x/cos_a,x/sin_a)\n",
        "      else:\n",
        "        # fully constrained case: crop touches all 4 sides\n",
        "        cos_2a = cos_a*cos_a - sin_a*sin_a\n",
        "        wr,hr = (w*cos_a - h*sin_a)/cos_2a, (h*cos_a - w*sin_a)/cos_2a\n",
        "\n",
        "      return wr,hr\n",
        "\n",
        "def random_rotation(x):\n",
        "    imgs = []\n",
        "    for i in x:\n",
        "        angle = np.random.randint(1,20)\n",
        "        wr, hr = _rotatedRectWithMaxArea(224,224,math.radians(angle))\n",
        "        # Use PIL or other library of the sort to rotate\n",
        "        i = imutils.rotate(np.array(i), angle=angle)\n",
        "        i = tf.image.central_crop(i, float(hr)/224) \n",
        "        i = tf.image.resize(i, [224,224])\n",
        "        imgs.append(i)\n",
        "    return np.array(imgs)\n",
        "\n",
        "\n",
        "def random_apply(func, x, p):\n",
        "    if tf.random.uniform([], minval=0, maxval=1) < p:\n",
        "        return func(x)\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "def custom_augment1(image):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = flip_random_crop(image)\n",
        "    image = random_apply(color_jitter, image, p=1)\n",
        "    return image\n",
        "\n",
        "def custom_augment2(image):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = flip_random_crop(image) \n",
        "    image = random_apply(color_jitter, image, p=0.7)\n",
        "    return image"
      ],
      "metadata": {
        "id": "CH97xmegxUbz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/sayakpaul/Barlow-Twins-TF\n",
        "%cd Barlow-Twins-TF"
      ],
      "metadata": {
        "id": "07Dtg-_euEmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Aux variables\n",
        "AUTO = tf.data.AUTOTUNE\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 75\n",
        "SEED = 42\n",
        "\n",
        "STEPS_PER_EPOCH = len(ssl_images) // BATCH_SIZE\n",
        "TOTAL_STEPS = STEPS_PER_EPOCH * EPOCHS\n",
        "WARMUP_EPOCHS = int(EPOCHS * 0.1)\n",
        "WARMUP_STEPS = int(WARMUP_EPOCHS * STEPS_PER_EPOCH)\n",
        "\n",
        "import lr_scheduler\n",
        "\n",
        "lr_decayed_fn = lr_scheduler.WarmUpCosine(\n",
        "    learning_rate_base=1e-3,\n",
        "    total_steps=EPOCHS * STEPS_PER_EPOCH,\n",
        "    warmup_learning_rate=0.0,\n",
        "    warmup_steps=WARMUP_STEPS\n",
        ")\n",
        "\n",
        "#Get transformations to apply to images\n",
        "def get_ssl_ds(dataset, rotA=False, rotB=False):\n",
        "  \"\"\"\n",
        "    datset: images to train during ssl phase\n",
        "    rotA and rotB: flags that indicate if rotation transformation should be applied              \n",
        "  \"\"\"\n",
        "  #get to copies of the same image to separate into two diferent sets \n",
        "  #the transformation applied to each set may not be the same\n",
        "  datasetA, datasetB = dataset, dataset\n",
        "  if rotA:\n",
        "    datasetA = random_apply(random_rotation,dataset, p=1)  \n",
        "  if rotB:\n",
        "    datasetB = random_apply(random_rotation,dataset, p=1)\n",
        "\n",
        "  ssl_ds_A = tf.data.Dataset.from_tensor_slices(datasetA)\n",
        "  ssl_ds_A = (\n",
        "      ssl_ds_A.shuffle(1024, seed=SEED)\n",
        "      .map(custom_augment1, num_parallel_calls=AUTO)\n",
        "      .batch(BATCH_SIZE)\n",
        "      .prefetch(AUTO)\n",
        "  )\n",
        "  \n",
        "  \n",
        "  ssl_ds_B = tf.data.Dataset.from_tensor_slices(datasetB)\n",
        "  ssl_ds_B = (\n",
        "      ssl_ds_B.shuffle(1024, seed=SEED)\n",
        "      .map(custom_augment2, num_parallel_calls=AUTO)\n",
        "      .batch(BATCH_SIZE)\n",
        "      .prefetch(AUTO)\n",
        "  )\n",
        "\n",
        "  # We then zip both of these datasets.\n",
        "  ssl_ds = tf.data.Dataset.zip((ssl_ds_A, ssl_ds_B))\n",
        "  return ssl_ds\n",
        "\n",
        "def off_diagonal(x):\n",
        "    n = tf.shape(x)[0]\n",
        "    flattened = tf.reshape(x, [-1])[:-1]\n",
        "    off_diagonals = tf.reshape(flattened, (n-1, n+1))[:, 1:]\n",
        "    return tf.reshape(off_diagonals, [-1])\n",
        "\n",
        "\n",
        "def normalize_repr(z):\n",
        "    z_norm = (z - tf.reduce_mean(z, axis=0)) / tf.math.reduce_std(z, axis=0)\n",
        "    return z_norm\n",
        "\n",
        "\n",
        "def compute_loss(z_a, z_b, lambd):\n",
        "    # Get batch size and representation dimension.\n",
        "    batch_size = tf.cast(tf.shape(z_a)[0], z_a.dtype)\n",
        "    repr_dim = tf.shape(z_a)[1]\n",
        "\n",
        "\n",
        "    # Normalize the representations along the batch dimension.\n",
        "    z_a_norm = normalize_repr(z_a)\n",
        "    z_b_norm = normalize_repr(z_b)\n",
        "\n",
        "    # Cross-correlation matrix.\n",
        "    c = tf.matmul(z_a_norm, z_b_norm, transpose_a=True) / batch_size\n",
        "\n",
        "    # Loss.\n",
        "    on_diag = (1) - tf.linalg.diag_part(c) \n",
        "    on_diag = tf.reduce_sum(tf.pow(on_diag, 2))\n",
        "    off_diag = off_diagonal(c)\n",
        "    off_diag = tf.reduce_sum(tf.pow(off_diag, 2))\n",
        "    loss = on_diag + (lambd * off_diag)\n",
        "    return loss \n"
      ],
      "metadata": {
        "id": "BbmTJkNKc3Jm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BarlowTwins(tf.keras.Model):\n",
        "    def __init__(self, encoder, lambd=5e-3):\n",
        "        super(BarlowTwins, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.lambd = lambd\n",
        "        self.loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.loss_tracker]\n",
        "\n",
        "    def train_step(self, data):\n",
        "        # Unpack the data.\n",
        "        ds_one, ds_two = data\n",
        "\n",
        "        # Forward pass through the encoder and predictor.\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_a, z_b = self.encoder(ds_one, training=True), self.encoder(ds_two, training=True)\n",
        "            loss = compute_loss(z_a, z_b, self.lambd) \n",
        "\n",
        "        # Compute gradients and update the parameters.\n",
        "        gradients = tape.gradient(loss, self.encoder.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.encoder.trainable_variables))\n",
        "\n",
        "        # Monitor loss.\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        return {\"loss\": self.loss_tracker.result()}"
      ],
      "metadata": {
        "id": "0cQ0IbwutdBU"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_decayed_fn)\n",
        "\n",
        "#Get model\n",
        "encoder = encoderModel(1024)\n",
        "barlow_twins = BarlowTwins(encoder)\n",
        "barlow_twins.compile(optimizer=optimizer)\n",
        "\n",
        "#apply transformations to the datasey\n",
        "ssl_ds = get_ssl_ds(ssl_images)\n",
        "\n",
        "# train network\n",
        "history = barlow_twins.fit(ssl_ds,\n",
        "                epochs=EPOCHS,\n",
        "                batch_size=128,\n",
        "                shuffle=True)\n",
        "\n",
        "\n",
        "# Save the model\n",
        "model_name = 'model_name'\n",
        "Pmodel = '/content/drive/MyDrive/Tese/code/Models/Self_supervised/' + model_name\n",
        "barlow_twins.encoder.save(Pmodel)"
      ],
      "metadata": {
        "id": "zsW7aCJrdNJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Supervised Phase**"
      ],
      "metadata": {
        "id": "5ulTfxMD7woV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create pretrain model\n",
        "def create_classifier(encoder, trainable=True):\n",
        "    for layer in encoder.layers:\n",
        "        layer.trainable = trainable\n",
        "\n",
        "    inputs = tf.keras.Input(shape=(224,224,3))\n",
        "    features = encoder(inputs)\n",
        "    features = layers.GlobalAveragePooling2D()(features)\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(features)\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"fire-classifier\")\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss=losses.BinaryCrossentropy(),\n",
        "        metrics=['accuracy'],\n",
        "    )\n",
        "    model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "EAUuoRGG70Lb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model for baseline (all layers are randomly initialized)\n",
        "def create_model():\n",
        "    inputs = tf.keras.Input(shape=(224,224,3))\n",
        "    features = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    features = layers.AveragePooling2D((2, 2), padding='same')(features)\n",
        "    features = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(features)\n",
        "    features = layers.AveragePooling2D((2, 2), padding='same')(features)\n",
        "    features = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(features)\n",
        "    features = layers.AveragePooling2D((2, 2), padding='same')(features)\n",
        "    features = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(features)\n",
        "    features = layers.AveragePooling2D((2, 2), padding='same')(features)\n",
        "    features = layers.Conv2D(64, (3, 3), activation='tanh', padding='same')(features)\n",
        "    features = layers.AveragePooling2D((2, 2), padding='same')(features)\n",
        "    \n",
        "    features = layers.GlobalAveragePooling2D()(features)\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(features)\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"fire-classifier\")\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss=losses.BinaryCrossentropy(),\n",
        "        metrics=['accuracy'],\n",
        "    )\n",
        "    return model"
      ],
      "metadata": {
        "id": "rOf2GfP5Tw-5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_evaluate_supervised(task, model_name, model_path, path_to_save, mode = True):\n",
        "  # Define per-fold score containers\n",
        "  acc_per_fold = []\n",
        "  loss_per_fold = []\n",
        "  f1score_per_fold = []\n",
        "  avg_per_fold = []\n",
        "\n",
        "\n",
        "  # Merge inputs and targets\n",
        "  inputs = np.array(sup_images)\n",
        "  targets = np.array(sup_labels)\n",
        "\n",
        "\n",
        "  num_folds = 10\n",
        "  # Define the K-fold Cross Validator\n",
        "  kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "  # K-fold Cross Validation model evaluation\n",
        "  fold_no = 1\n",
        "\n",
        "  #aux variables \n",
        "  true_labs =[]\n",
        "  predict_labs = []\n",
        "  predict_orig_labs = []\n",
        "\n",
        "\n",
        "  path_name = model_path + model_name\n",
        "  #----------TRAIN SUPERVISED LAYERS-----------------#\n",
        "  for train, test in kfold.split(inputs, targets):\n",
        "    \n",
        "    model = load_model(path_name)\n",
        "    #For barlow twins and autoencoder it's necessary to remove some layers (simclr only saves encoder component) \n",
        "    #remove 6 layers for autoencoder and 8 for barlow twins\n",
        "    if task == 'autoencoder':\n",
        "      model.pop()\n",
        "      model.pop()\n",
        "      model.pop()\n",
        "      model.pop()\n",
        "      model.pop()\n",
        "      model.pop()\n",
        "    elif task == 'BT':\n",
        "      model.pop()\n",
        "      model.pop()\n",
        "      model.pop()\n",
        "      model.pop()\n",
        "      model.pop()\n",
        "      model.pop()\n",
        "      model.pop()  \n",
        "      model.pop() \n",
        "\n",
        "\n",
        "    if task == 'Baseline':\n",
        "      classifier = create_model()\n",
        "\n",
        "    #If training and evaluating pretrained model  \n",
        "    else:\n",
        "      encoder = tf.keras.Sequential()\n",
        "      for layer in model.layers:\n",
        "        encoder.add(layer)\n",
        "      \n",
        "      classifier = create_classifier(encoder, trainable=mode)\n",
        "\n",
        "\n",
        "    #get the racio between positive and negative examples\n",
        "    pos = sum(targets[train])\n",
        "    w_pos = len(targets[train])/(pos*2)\n",
        "    w_neg = len(targets[train])/((len(targets[train])-pos)*2)\n",
        "    class_weights = {0: w_neg, 1:w_pos}\n",
        "    # Generate a print\n",
        "    print('------------------------------------------------------------------------')\n",
        "    print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "    # Fit data to model\n",
        "    history = classifier.fit(inputs[train], targets[train], batch_size=32, epochs=75, class_weight=class_weights, callbacks=[])\n",
        "\n",
        "    # Generate generalization metrics\n",
        "    scores = classifier.evaluate(inputs[test], targets[test], verbose=0)\n",
        "    print(f'Score for fold {fold_no}: {classifier.metrics_names[0]} of {scores[0]}; {classifier.metrics_names[1]} of {scores[1]*100}%')\n",
        "    \n",
        "    acc_per_fold.append(scores[1] * 100)\n",
        "    loss_per_fold.append(scores[0])\n",
        "    predict_orig = classifier.predict(inputs[test])\n",
        "    predict = tf.round(predict_orig)\n",
        "    if len(predict_labs) == 0:\n",
        "      true_labs = targets[test]\n",
        "      predict_labs = predict\n",
        "      predict_orig_labs = predict_orig \n",
        "    else:\n",
        "      predict_orig_labs = np.concatenate((predict_orig_labs, predict_orig), axis=0)\n",
        "      predict_labs = np.concatenate((predict_labs, predict), axis=0)\n",
        "      true_labs = np.concatenate((true_labs, targets[test]), axis=0)\n",
        "    \n",
        "\n",
        "    \n",
        "    print('------------------------------------------------------------------------')\n",
        "    matrix = confusion_matrix(targets[test], predict)\n",
        "    print(f'> Confusion matrix: {matrix}')\n",
        "    print('------------------------------------------------------------------------')\n",
        "    f1score_per_fold.append(f1_score(targets[test], predict))\n",
        "    print(f'> F1 score: {f1score_per_fold[fold_no-1]}')\n",
        "    print('------------------------------------------------------------------------')\n",
        "    avg_per_fold.append(average_precision_score(targets[test], predict_orig))\n",
        "    print('------------------------------------------------------------------------')\n",
        "    print(f'> Avg precision: {avg_per_fold[fold_no-1]}')\n",
        "    print('------------------------------------------------------------------------')\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.title(\"Loss\")\n",
        "    plt.show()\n",
        "    plt.figure()\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.title(\"Acc\")\n",
        "    plt.show()\n",
        "\n",
        "    \n",
        "    # Increase fold number\n",
        "    fold_no = fold_no + 1\n",
        "\n",
        "\n",
        "  # == Provide average scores ==\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print('Score per fold')\n",
        "  for i in range(0, len(acc_per_fold)):\n",
        "    print('------------------------------------------------------------------------')\n",
        "    print(f'> Fold {i+1} -  Accuracy: {acc_per_fold[i]}%  - F1score: {f1score_per_fold[i]}')\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print('Average scores for all folds:')\n",
        "  print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "  print(f'> Loss: {np.mean(loss_per_fold)} (+- {np.std(loss_per_fold)})')\n",
        "  print(f'> F1score: {np.mean(f1score_per_fold)} (+- {np.std(f1score_per_fold)})')\n",
        "  print(f'> Avg precision: {np.mean(avg_per_fold)} (+- {np.std(avg_per_fold)})')\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Median: {median(acc_per_fold)}')\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print('Confusion Matrix:')\n",
        "  matrix = confusion_matrix(true_labs, predict_labs)\n",
        "  print(f'> Confusion matrix: {matrix}')\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print('F1 score:')\n",
        "  f1score = f1_score(true_labs, predict_labs)\n",
        "\n",
        "  print(f'> F1 score: {f1score}')\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print('------------------------------------------------------------------------')\n",
        "  avg_precision_final = average_precision_score(true_labs, predict_orig_labs)\n",
        "  print(f'> Avg precision: {avg_precision_final}')\n",
        "  print('------------------------------------------------------------------------')\n",
        "\n",
        "\n",
        "  #save csv file with results\n",
        "  import csv \n",
        "  folder_path = path_to_save + model_name + '.csv' \n",
        "  header = ['accuracy', 'f1score', 'avg_precision']\n",
        "  with open(folder_path,'w') as fd:\n",
        "      writer = csv.writer(fd)\n",
        "      # write the header\n",
        "      writer.writerow(header)\n",
        "      for i in range(len(acc_per_fold)):\n",
        "        row = [acc_per_fold[i], f1score_per_fold[i], avg_per_fold[i]]\n",
        "        writer.writerow(row)"
      ],
      "metadata": {
        "id": "uFuwBU2Y9dqf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'model_name'\n",
        "model_path = '/content/drive/MyDrive/Tese/code/Models/Self_supervised/'\n",
        "path_to_save = '/content/drive/MyDrive/Tese/code/results/' \n",
        "task = 'SimCLR'  #options: [autoencoder, SimCLR, BT, Baseline]\n",
        "\n",
        "train_evaluate_supervised(task, model_name, model_path, path_to_save, True)"
      ],
      "metadata": {
        "id": "4v_SpnKn9rmH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}